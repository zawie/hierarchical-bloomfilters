\newcommand{\sep}{\hspace*{0.15in}}
\newcommand\cell{%%
    \fbox{\rule{0.15in}{0pt}\rule[-0.5ex]{0pt}{0.15in}}}

\subsection{Standard Implementation}
Before we discuss the proposed solution, let us review the standard implementation.
The standard implementation allocates a bit vector of size $m$ bits. Typically, this is set to be $\times 10$ the expected number of elements it will hold.

\begin{center}
    \textit{Standard Bloom Filter}
    \vspace{10pt}\\
    $\text{Bit Vector: } \cell\cell\cell\cell\cell\cell\cell\cell\cell\cell\cell\cell \ldots$
    \vspace{10pt}\\
\end{center}

Per the standard implementation, to insert an element we hash the element $k$ times and set the corresponding bit in the vector.
To query, we simply read instead of set the bit.
Notice, that if $m$ is sufficiently large, it will span accross multiple pages of memory. 
Thus, when we read and write to the underlying bit vector, we may page fault for every bit set ($k$ times), slowing down our insertions or queries.

\subsection{Proposed Hierarchical Implementation}
Our proposal is to allocate $w$ bit vectors of size $P$ bits, where $P$ is computer system's page size in bits and $w$ is an integer such that $m = w P$.
Notice, our proposed implementation uses the same amount of memory, but  splits the bit vector into page size chunks.

\begin{center}
    \textit{Hierarchical Bloom Filter}
    \vspace{10pt}\\
    $\text{Bit Vector 1: }\cell\cell\cell\cell \sep \text{Bit Vector 2: }\cell\cell\cell\cell \sep \ldots \sep \text{Bit Vector $w$: }\cell\cell\cell\cell$
    \vspace{10pt}\\
\end{center}

To insert, hash the element $l$ times mod $w$ and insert the element per the standard bloom filter operations to the corresponding bit vector.
Each bit vector (bloom filter) has $k$ hash functions associated with it.
Here $l$ is a pre-determined parameter of the datastructure; we will dicuss what the optimal setting is in a following section.
To query, we simply query the corresponding bit vector instead of inserting.
In essence, our proposal to create a bloom filter of bloom filters, hence the name.

Notice, for any given insertion or query, we have to perform $l$ more hash operations than the standard implementation. 
This is not a concern if we select sufficiently cheap hash functions.
More importantly, since each bit vector is on it's own page of memory, we expect to page fault at most $l$ times.
 Thus, if we minimize $l$ without sacrificing effectiveness, we will reduce the expected number of page faults and increase the data structures efficiency.